{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection with Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa \n",
    "from scipy.io import wavfile as wav\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract an MFCC for each cough audio file in the dataset and store it in a Panda Dataframe along with it's class label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfccs(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsnorm = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"file could not be loaded: \", file)\n",
    "        return None \n",
    "     \n",
    "    return mfccsnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the cough dataset \n",
    "fulldatasetpath = 'C:\\\\Users\\\\Documents\\\\Cough Detection\\\\Data\\\\cough\\\\'\n",
    "\n",
    "metadata = pd.read_csv('C:\\\\Users\\\\Documents\\\\Cough Detection\\\\Data\\\\cough.csv')\n",
    "\n",
    "features = []\n",
    "\n",
    "# Iterate through each sound file and extract the features \n",
    "for index, row in metadata.iterrows():\n",
    "    \n",
    "    file_name = os.path.join(os.path.abspath(fulldatasetpath),str(row[\"file_name\"]))\n",
    "    \n",
    "    class_label = row[\"class_name\"]\n",
    "    data = extract_mfccs(file_name)\n",
    "    \n",
    "    features.append([data, class_label])\n",
    "\n",
    "# Convert into a Panda dataframe \n",
    "featuresdataframe = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "print('features extracted from ', len(featuresdataframe), ' files') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               feature class_label\n",
      "0    [-200.70184, 99.20585, -72.28148, 21.80312, -9...       cough\n",
      "1    [-314.28616, 90.3109, -68.50514, 15.40077, -12...       cough\n",
      "2    [-314.4416, 93.78775, -13.789625, 2.641592, -5...       cough\n",
      "3    [-310.52585, 71.25459, -68.1882, -6.732506, 1....       cough\n",
      "4    [-256.3385, 131.29033, -78.243164, 8.587592, 1...       cough\n",
      "..                                                 ...         ...\n",
      "995  [-250.20494, 186.81802, -40.3024, -2.6410193, ...       cough\n",
      "996  [-277.06705, 167.86713, -2.8843956, 1.5124706,...       cough\n",
      "997  [-296.343, 167.84077, -85.02909, 25.053547, -3...       cough\n",
      "998  [-196.3671, 159.38153, -61.271618, 39.612797, ...       cough\n",
      "999  [-430.52194, 184.45177, -46.895187, -42.32516,...       cough\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(featuresdataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the categorical text data into model-understandable numerical data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert features and Class labels into numpy arrays\n",
    "X = np.array(featuresdataframe.feature.tolist())\n",
    "y = np.array(featuresdataframe.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "labelen = LabelEncoder()\n",
    "classen = to_categorical(labelen.fit_transform(y)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into training and testing sets. The testing set size will be 10% and we will set a random state. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, classen, test_size=0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train count: 900\n"
     ]
    }
   ],
   "source": [
    "print(f\"train count: {len(x_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "input_dim = x_train.shape[1]\n",
    "print(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print(X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Autoencoder Model with L1 Sparsity Penalty as 1e-5 and Loss function as MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 512)               20992     \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 224)               114912    \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 512)               115200    \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 40)                20520     \n",
      "=================================================================\n",
      "Total params: 271,624\n",
      "Trainable params: 271,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=X.shape[1], activity_regularizer=l1(0.00001), activation='relu'))\n",
    "model.add(Dense(224, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(X.shape[1])) # Multiple output neurons\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900 samples\n",
      "Epoch 1/90\n",
      "900/900 [==============================] - 0s 435us/sample - loss: 875.7804 - accuracy: 0.9244\n",
      "Epoch 2/90\n",
      "900/900 [==============================] - 0s 66us/sample - loss: 81.3038 - accuracy: 0.9967\n",
      "Epoch 3/90\n",
      "900/900 [==============================] - 0s 69us/sample - loss: 46.5264 - accuracy: 0.9900\n",
      "Epoch 4/90\n",
      "900/900 [==============================] - 0s 70us/sample - loss: 31.9904 - accuracy: 0.9878\n",
      "Epoch 5/90\n",
      "900/900 [==============================] - 0s 71us/sample - loss: 23.7607 - accuracy: 0.9911\n",
      "Epoch 6/90\n",
      "900/900 [==============================] - 0s 70us/sample - loss: 18.5942 - accuracy: 0.9889\n",
      "Epoch 7/90\n",
      "900/900 [==============================] - 0s 68us/sample - loss: 14.1450 - accuracy: 0.9889\n",
      "Epoch 8/90\n",
      "900/900 [==============================] - 0s 72us/sample - loss: 11.2297 - accuracy: 0.9878\n",
      "Epoch 9/90\n",
      "900/900 [==============================] - 0s 71us/sample - loss: 9.1948 - accuracy: 0.9911\n",
      "Epoch 10/90\n",
      "900/900 [==============================] - 0s 71us/sample - loss: 7.5379 - accuracy: 0.9889\n",
      "Epoch 11/90\n",
      "900/900 [==============================] - 0s 71us/sample - loss: 6.3290 - accuracy: 0.9900\n",
      "Epoch 12/90\n",
      "900/900 [==============================] - 0s 69us/sample - loss: 5.7061 - accuracy: 0.9900\n",
      "Epoch 13/90\n",
      "900/900 [==============================] - 0s 72us/sample - loss: 4.8516 - accuracy: 0.9889\n",
      "Epoch 14/90\n",
      "900/900 [==============================] - 0s 70us/sample - loss: 4.2958 - accuracy: 0.9889\n",
      "Epoch 15/90\n",
      "900/900 [==============================] - 0s 66us/sample - loss: 3.6359 - accuracy: 0.9922\n",
      "Epoch 16/90\n",
      "900/900 [==============================] - 0s 72us/sample - loss: 3.3335 - accuracy: 0.9889\n",
      "Epoch 17/90\n",
      "900/900 [==============================] - 0s 73us/sample - loss: 3.1537 - accuracy: 0.9922\n",
      "Epoch 18/90\n",
      "900/900 [==============================] - 0s 68us/sample - loss: 2.7649 - accuracy: 0.9900\n",
      "Epoch 19/90\n",
      "900/900 [==============================] - 0s 68us/sample - loss: 2.8856 - accuracy: 0.9922\n",
      "Epoch 20/90\n",
      "900/900 [==============================] - 0s 76us/sample - loss: 2.4108 - accuracy: 0.9900\n",
      "Epoch 21/90\n",
      "900/900 [==============================] - 0s 72us/sample - loss: 2.0399 - accuracy: 0.9900\n",
      "Epoch 22/90\n",
      "900/900 [==============================] - 0s 69us/sample - loss: 2.0276 - accuracy: 0.9900\n",
      "Epoch 23/90\n",
      "900/900 [==============================] - 0s 72us/sample - loss: 2.0431 - accuracy: 0.9922\n",
      "Epoch 24/90\n",
      "900/900 [==============================] - 0s 75us/sample - loss: 1.8748 - accuracy: 0.9889\n",
      "Epoch 25/90\n",
      "900/900 [==============================] - 0s 79us/sample - loss: 1.5420 - accuracy: 0.9900\n",
      "Epoch 26/90\n",
      "900/900 [==============================] - 0s 82us/sample - loss: 1.5036 - accuracy: 0.9911\n",
      "Epoch 27/90\n",
      "900/900 [==============================] - 0s 83us/sample - loss: 1.3988 - accuracy: 0.9911\n",
      "Epoch 28/90\n",
      "900/900 [==============================] - 0s 80us/sample - loss: 1.4947 - accuracy: 0.9900\n",
      "Epoch 29/90\n",
      "900/900 [==============================] - 0s 81us/sample - loss: 1.1890 - accuracy: 0.9911\n",
      "Epoch 30/90\n",
      "900/900 [==============================] - 0s 80us/sample - loss: 1.0843 - accuracy: 0.9911\n",
      "Epoch 31/90\n",
      "900/900 [==============================] - 0s 74us/sample - loss: 1.0527 - accuracy: 0.9900\n",
      "Epoch 32/90\n",
      "900/900 [==============================] - 0s 75us/sample - loss: 0.9955 - accuracy: 0.9900\n",
      "Epoch 33/90\n",
      "900/900 [==============================] - 0s 66us/sample - loss: 1.0760 - accuracy: 0.9911\n",
      "Epoch 34/90\n",
      "900/900 [==============================] - 0s 70us/sample - loss: 0.9541 - accuracy: 0.9922\n",
      "Epoch 35/90\n",
      "900/900 [==============================] - 0s 73us/sample - loss: 0.8197 - accuracy: 0.9911\n",
      "Epoch 36/90\n",
      "900/900 [==============================] - 0s 66us/sample - loss: 1.1141 - accuracy: 0.9911\n",
      "Epoch 37/90\n",
      "900/900 [==============================] - 0s 69us/sample - loss: 0.9799 - accuracy: 0.9911\n",
      "Epoch 38/90\n",
      "900/900 [==============================] - 0s 73us/sample - loss: 0.7500 - accuracy: 0.9900\n",
      "Epoch 39/90\n",
      "900/900 [==============================] - 0s 82us/sample - loss: 0.6527 - accuracy: 0.9933\n",
      "Epoch 40/90\n",
      "900/900 [==============================] - 0s 81us/sample - loss: 0.7191 - accuracy: 0.9900\n",
      "Epoch 41/90\n",
      "900/900 [==============================] - 0s 81us/sample - loss: 0.8239 - accuracy: 0.9911\n",
      "Epoch 42/90\n",
      "900/900 [==============================] - 0s 81us/sample - loss: 0.7868 - accuracy: 0.9911\n",
      "Epoch 43/90\n",
      "900/900 [==============================] - 0s 75us/sample - loss: 0.7503 - accuracy: 0.9911\n",
      "Epoch 44/90\n",
      "900/900 [==============================] - 0s 69us/sample - loss: 0.5969 - accuracy: 0.9900\n",
      "Epoch 45/90\n",
      "900/900 [==============================] - 0s 81us/sample - loss: 0.6285 - accuracy: 0.9922\n",
      "Epoch 46/90\n",
      "900/900 [==============================] - 0s 80us/sample - loss: 0.7710 - accuracy: 0.9900\n",
      "Epoch 47/90\n",
      "900/900 [==============================] - 0s 86us/sample - loss: 1.0722 - accuracy: 0.9911\n",
      "Epoch 48/90\n",
      "900/900 [==============================] - 0s 78us/sample - loss: 0.8208 - accuracy: 0.9922\n",
      "Epoch 49/90\n",
      "900/900 [==============================] - 0s 71us/sample - loss: 0.6523 - accuracy: 0.9900\n",
      "Epoch 50/90\n",
      "900/900 [==============================] - 0s 66us/sample - loss: 0.4989 - accuracy: 0.9922\n",
      "Epoch 51/90\n",
      "900/900 [==============================] - 0s 69us/sample - loss: 0.4463 - accuracy: 0.9900\n",
      "Epoch 52/90\n",
      "900/900 [==============================] - 0s 76us/sample - loss: 0.4037 - accuracy: 0.9922\n",
      "Epoch 53/90\n",
      "900/900 [==============================] - 0s 76us/sample - loss: 0.4070 - accuracy: 0.9911\n",
      "Epoch 54/90\n",
      "900/900 [==============================] - 0s 65us/sample - loss: 0.4764 - accuracy: 0.9900\n",
      "Epoch 55/90\n",
      "900/900 [==============================] - 0s 70us/sample - loss: 0.5730 - accuracy: 0.9911\n",
      "Epoch 56/90\n",
      "900/900 [==============================] - 0s 76us/sample - loss: 0.5762 - accuracy: 0.9911\n",
      "Epoch 57/90\n",
      "900/900 [==============================] - 0s 82us/sample - loss: 0.8958 - accuracy: 0.9911\n",
      "Epoch 58/90\n",
      "900/900 [==============================] - 0s 78us/sample - loss: 1.3797 - accuracy: 0.9956\n",
      "Epoch 59/90\n",
      "900/900 [==============================] - 0s 65us/sample - loss: 0.6708 - accuracy: 0.9911\n",
      "Epoch 60/90\n",
      "900/900 [==============================] - 0s 68us/sample - loss: 0.5015 - accuracy: 0.9900\n",
      "Epoch 61/90\n",
      "900/900 [==============================] - 0s 76us/sample - loss: 0.7252 - accuracy: 0.9933\n",
      "Epoch 62/90\n",
      "900/900 [==============================] - 0s 69us/sample - loss: 0.7973 - accuracy: 0.9922\n",
      "Epoch 63/90\n",
      "900/900 [==============================] - 0s 71us/sample - loss: 0.4073 - accuracy: 0.9933\n",
      "Epoch 64/90\n",
      "900/900 [==============================] - 0s 66us/sample - loss: 0.3145 - accuracy: 0.9911\n",
      "Epoch 65/90\n",
      "900/900 [==============================] - 0s 68us/sample - loss: 0.4166 - accuracy: 0.9900\n",
      "Epoch 66/90\n",
      "900/900 [==============================] - 0s 70us/sample - loss: 0.3660 - accuracy: 0.9922\n",
      "Epoch 67/90\n",
      "900/900 [==============================] - 0s 73us/sample - loss: 0.6902 - accuracy: 0.9900\n",
      "Epoch 68/90\n",
      "900/900 [==============================] - 0s 86us/sample - loss: 1.6581 - accuracy: 0.9911\n",
      "Epoch 69/90\n",
      "900/900 [==============================] - 0s 84us/sample - loss: 3.0023 - accuracy: 0.9911\n",
      "Epoch 70/90\n",
      "900/900 [==============================] - 0s 68us/sample - loss: 2.3440 - accuracy: 0.9900\n",
      "Epoch 71/90\n",
      "900/900 [==============================] - 0s 72us/sample - loss: 0.6344 - accuracy: 0.9889\n",
      "Epoch 72/90\n",
      "900/900 [==============================] - 0s 79us/sample - loss: 0.4188 - accuracy: 0.9900\n",
      "Epoch 73/90\n",
      "900/900 [==============================] - 0s 83us/sample - loss: 0.2858 - accuracy: 0.9922\n",
      "Epoch 74/90\n",
      "900/900 [==============================] - 0s 90us/sample - loss: 0.2534 - accuracy: 0.9922\n",
      "Epoch 75/90\n",
      "900/900 [==============================] - 0s 69us/sample - loss: 0.3432 - accuracy: 0.9900\n",
      "Epoch 76/90\n",
      "900/900 [==============================] - 0s 66us/sample - loss: 2.9678 - accuracy: 0.9900\n",
      "Epoch 77/90\n",
      "900/900 [==============================] - 0s 69us/sample - loss: 1.2926 - accuracy: 0.9922\n",
      "Epoch 78/90\n",
      "900/900 [==============================] - 0s 89us/sample - loss: 1.0645 - accuracy: 0.9889\n",
      "Epoch 79/90\n",
      "900/900 [==============================] - 0s 72us/sample - loss: 0.7197 - accuracy: 0.9911\n",
      "Epoch 80/90\n",
      "900/900 [==============================] - 0s 68us/sample - loss: 0.5507 - accuracy: 0.9889\n",
      "Epoch 81/90\n",
      "900/900 [==============================] - 0s 66us/sample - loss: 0.6599 - accuracy: 0.9933\n",
      "Epoch 82/90\n",
      "900/900 [==============================] - 0s 65us/sample - loss: 0.4517 - accuracy: 0.9911\n",
      "Epoch 83/90\n",
      "900/900 [==============================] - 0s 69us/sample - loss: 0.3876 - accuracy: 0.9922\n",
      "Epoch 84/90\n",
      "900/900 [==============================] - 0s 72us/sample - loss: 0.3621 - accuracy: 0.9911\n",
      "Epoch 85/90\n",
      "900/900 [==============================] - 0s 75us/sample - loss: 0.3487 - accuracy: 0.9911\n",
      "Epoch 86/90\n",
      "900/900 [==============================] - 0s 79us/sample - loss: 0.4014 - accuracy: 0.9911\n",
      "Epoch 87/90\n",
      "900/900 [==============================] - 0s 80us/sample - loss: 0.4798 - accuracy: 0.9911\n",
      "Epoch 88/90\n",
      "900/900 [==============================] - 0s 78us/sample - loss: 0.2784 - accuracy: 0.9933\n",
      "Epoch 89/90\n",
      "900/900 [==============================] - 0s 80us/sample - loss: 0.3808 - accuracy: 0.9933\n",
      "Epoch 90/90\n",
      "900/900 [==============================] - 0s 76us/sample - loss: 0.4518 - accuracy: 0.9900\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,x_train,verbose=1,epochs=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train loss')\n",
    "#plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the MSE for the Test Dataset (out of sample) and on the Whole Dataset (In + Out Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of Sample Score (RMSE): 0.6133102178573608\n",
      "Insample Normal Score (RMSE): 0.5205418467521667\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_test)\n",
    "score1 = np.sqrt(metrics.mean_squared_error(pred,x_test))\n",
    "pred = model.predict(X)\n",
    "score2 = np.sqrt(metrics.mean_squared_error(pred,X))\n",
    "\n",
    "print(f\"Out of Sample Score (RMSE): {score1}\")\n",
    "print(f\"Insample Normal Score (RMSE): {score2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the model to predict the MSE for validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'C:\\\\Users\\\\\\\\Documents\\\\Audio Classification\\\\Evaluation audio\\\\siren_1.wav' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfccs(filename):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsnorm = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"file could not be loaded: \", file)\n",
    "        return None \n",
    "     \n",
    "    return mfccsnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_feature = extract_mfccs(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack Underway Score (RMSE): 1.4563369750976562\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(prediction_feature)\n",
    "score3 = np.sqrt(metrics.mean_squared_error(pred,prediction_feature))\n",
    "print(f\"Validation sample (RMSE): {score3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:\\\\Users\\\\\\\\Documents\\\\Cough Detection\\\\Data\\\\autoencoder_model_4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
